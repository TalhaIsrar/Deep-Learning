{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Ayl-Gre_dkVm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.nn import Module\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "mH82pLBrevuO"
   },
   "outputs": [],
   "source": [
    "#Normal Model\n",
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "wU0VZYvqe0IS",
    "outputId": "4f63b4ea-d1e7-4e98-b269-a3c66368d2c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 2.3026349544525146\n",
      "idx: 50, loss: 2.2941477298736572\n",
      "idx: 100, loss: 2.2012548446655273\n",
      "idx: 150, loss: 1.2413570880889893\n",
      "idx: 200, loss: 0.5782398581504822\n",
      "accuracy: 0.78\n",
      "idx: 0, loss: 0.6540509462356567\n",
      "idx: 50, loss: 0.447021484375\n",
      "idx: 100, loss: 0.5069711804389954\n",
      "idx: 150, loss: 0.5374249815940857\n",
      "idx: 200, loss: 0.31400439143180847\n",
      "accuracy: 0.84\n",
      "idx: 0, loss: 0.4617568254470825\n",
      "idx: 50, loss: 0.3370366394519806\n",
      "idx: 100, loss: 0.44619306921958923\n",
      "idx: 150, loss: 0.46176448464393616\n",
      "idx: 200, loss: 0.29563072323799133\n",
      "accuracy: 0.86\n",
      "idx: 0, loss: 0.4282064735889435\n",
      "idx: 50, loss: 0.3117685616016388\n",
      "idx: 100, loss: 0.4261307716369629\n",
      "idx: 150, loss: 0.4244333505630493\n",
      "idx: 200, loss: 0.2847810685634613\n",
      "accuracy: 0.86\n",
      "idx: 0, loss: 0.4109957218170166\n",
      "idx: 50, loss: 0.2945746183395386\n",
      "idx: 100, loss: 0.41346248984336853\n",
      "idx: 150, loss: 0.40534743666648865\n",
      "idx: 200, loss: 0.2772273123264313\n",
      "accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    batch_size = 256\n",
    "    train_dataset = mnist.MNIST(download=True, root='./data', train=True, transform=ToTensor())\n",
    "    test_dataset = mnist.MNIST(download=True, root='./data', train=False, transform=ToTensor())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    model = Model()\n",
    "    sgd = SGD(model.parameters(), lr=1e-1)\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    all_epoch = 5\n",
    "\n",
    "    for current_epoch in range(all_epoch):\n",
    "        model.train()\n",
    "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "            sgd.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = loss_fn(predict_y, train_label.long())\n",
    "            if idx % 50 == 0:\n",
    "                print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "\n",
    "        all_correct_num = 0\n",
    "        all_sample_num = 0\n",
    "        model.eval()\n",
    "        for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "            predict_y = model(test_x.float()).detach()\n",
    "            predict_y = np.argmax(predict_y, axis=-1)\n",
    "            current_correct_num = predict_y == test_label\n",
    "            all_correct_num += np.sum(current_correct_num.numpy(), axis=-1)\n",
    "            all_sample_num += current_correct_num.shape[0]\n",
    "        acc = all_correct_num / all_sample_num\n",
    "        print('accuracy: {:.2f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "tF9sj1quhNwD"
   },
   "outputs": [],
   "source": [
    "from brevitas.nn import QuantLinear\n",
    "from brevitas.quant import Int8ActPerTensorFloat\n",
    "from brevitas.quant import Int8WeightPerTensorFloat\n",
    "from brevitas.quant import Int8Bias\n",
    "from brevitas.nn import QuantIdentity\n",
    "from brevitas.nn import QuantReLU\n",
    "from brevitas.nn import QuantConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "-uvVrmEvhDTz"
   },
   "outputs": [],
   "source": [
    "#Making model with brevitas\n",
    "class Brevitas_Model(Module):\n",
    "    def __init__(self):\n",
    "        super(Brevitas_Model, self).__init__()\n",
    "        self.identity = QuantIdentity(return_quant_tensor=True)\n",
    "        self.conv1 = self.conv1 = QuantConv2d(1, 6, 5, bias=True, input_quant=Int8ActPerTensorFloat, weight_quant=Int8WeightPerTensorFloat,\n",
    "                                      output_quant=Int8ActPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.relu1 = QuantReLU(return_quant_tensor=True)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = QuantConv2d(6, 16, 5, bias=True, input_quant=Int8ActPerTensorFloat, weight_quant=Int8WeightPerTensorFloat,\n",
    "                                output_quant=Int8ActPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.relu2 = QuantReLU(return_quant_tensor=True)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = QuantLinear(256, 120, bias=True, input_quant=Int8ActPerTensorFloat, weight_quant=Int8WeightPerTensorFloat,\n",
    "                                output_quant=Int8ActPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.relu3 = QuantReLU(return_quant_tensor=True)\n",
    "        self.fc2 = QuantLinear(120, 84, bias=True, input_quant=Int8ActPerTensorFloat, weight_quant=Int8WeightPerTensorFloat,\n",
    "                                output_quant=Int8ActPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.relu4 = QuantReLU(return_quant_tensor=True)\n",
    "        self.fc3 = QuantLinear(84, 10, bias=True, input_quant=Int8ActPerTensorFloat, weight_quant=Int8WeightPerTensorFloat,\n",
    "                                output_quant=Int8ActPerTensorFloat, bias_quant=Int8Bias, return_quant_tensor=True)\n",
    "        self.relu5 = QuantReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.identity(x)\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu3(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu4(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu5(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "BDZ7Cm-gmdbo",
    "outputId": "189e235b-4ace-4031-ee34-9f2a7a8618a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 2.302600860595703\n",
      "idx: 50, loss: 2.290087938308716\n",
      "idx: 100, loss: 2.1032142639160156\n",
      "idx: 150, loss: 1.774557113647461\n",
      "idx: 200, loss: 1.0252306461334229\n",
      "accuracy: 0.68\n",
      "idx: 0, loss: 0.9428538084030151\n",
      "idx: 50, loss: 0.8009646534919739\n",
      "idx: 100, loss: 0.7890003323554993\n",
      "idx: 150, loss: 0.8983732461929321\n",
      "idx: 200, loss: 0.5346361994743347\n",
      "accuracy: 0.74\n",
      "idx: 0, loss: 0.7262919545173645\n",
      "idx: 50, loss: 0.6671064496040344\n",
      "idx: 100, loss: 0.7094277143478394\n",
      "idx: 150, loss: 0.6719374060630798\n",
      "idx: 200, loss: 0.49384498596191406\n",
      "accuracy: 0.75\n",
      "idx: 0, loss: 0.6772816777229309\n",
      "idx: 50, loss: 0.6196312308311462\n",
      "idx: 100, loss: 0.6735409498214722\n",
      "idx: 150, loss: 0.6238174438476562\n",
      "idx: 200, loss: 0.47341811656951904\n",
      "accuracy: 0.73\n",
      "idx: 0, loss: 0.7591606974601746\n",
      "idx: 50, loss: 0.5993204712867737\n",
      "idx: 100, loss: 0.650047242641449\n",
      "idx: 150, loss: 0.3051925003528595\n",
      "idx: 200, loss: 0.2878704369068146\n",
      "accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    batch_size = 256\n",
    "    train_dataset = mnist.MNIST(download=True, root='./data', train=True, transform=ToTensor())\n",
    "    test_dataset = mnist.MNIST(download=True, root='./data', train=False, transform=ToTensor())\n",
    "    trin_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    model = Brevitas_Model()\n",
    "    sgd = SGD(model.parameters(), lr=1e-1)\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    all_epoch = 5\n",
    "\n",
    "    for current_epoch in range(all_epoch):\n",
    "        model.train()\n",
    "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "            sgd.zero_grad()\n",
    "            predict_y = model(train_x.float())\n",
    "            loss = loss_fn(predict_y, train_label.long())\n",
    "            if idx % 50 == 0:\n",
    "                print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "            loss.backward()\n",
    "            sgd.step()\n",
    "\n",
    "        all_correct_num = 0\n",
    "        all_sample_num = 0\n",
    "        model.eval()\n",
    "        for idx, (test_x, test_label) in enumerate(test_loader):\n",
    "            predict_y = model(test_x.float()).detach()\n",
    "            predict_y = np.argmax(predict_y, axis=-1)\n",
    "            current_correct_num = predict_y == test_label\n",
    "            all_correct_num += np.sum(current_correct_num.numpy(), axis=-1)\n",
    "            all_sample_num += current_correct_num.shape[0]\n",
    "        acc = all_correct_num / all_sample_num\n",
    "        print('accuracy: {:.2f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lenet_quantized.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
